{
    "tokenizers_test.py::test_hf_wordpiece_tokenizers_outputs": 0.9423076923076923,
    "tokenizers_test.py::test_hf_wordpiece_tokenizers_multiple_strings": 0.641025641025641,
    "tokenizers_test.py::test_sentencepiece_model_tokenizer": 0.4,
    "tokenizers_test.py::test_sentencepiece_model_detokenizer": 0.5458333333333334,
    "tokenizers_test.py::test_hf_bpe_tokenizers_outputs": 0.846875,
    "tokenizers_test.py::test_bpe_detokenizer": 0.93125,
    "tokenizers_test.py::test_": 0.7527970165157165,
    "tokenizers_test.py::test_tiktoken_tokenizers": 0.9
}
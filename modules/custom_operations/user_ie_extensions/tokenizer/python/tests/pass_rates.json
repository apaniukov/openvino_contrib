{
    "tokenizers_test.py::test_hf_wordpiece_tokenizers_outputs": 0.9423076923076923,
    "tokenizers_test.py::test_hf_wordpiece_tokenizers_multiple_strings": 0.641025641025641,
    "tokenizers_test.py::test_sentencepiece_model_tokenizer": 0.6875,
    "tokenizers_test.py::test_sentencepiece_model_detokenizer": 0.5525,
    "tokenizers_test.py::test_hf_bpe_tokenizers_outputs": 0.846875,
    "tokenizers_test.py::test_bpe_detokenizer": 0.93125,
    "tokenizers_test.py::test_tiktoken_tokenizers": 0.9,
    "tokenizers_test.py::test_": 0.7761194029850746
}